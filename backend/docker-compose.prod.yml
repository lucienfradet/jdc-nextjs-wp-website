services:
  # ============================================
  # CRITICAL: Payment Processing Path
  # ============================================

  # Next.js Instance 1
  nextjs-1:
    image: ghcr.io/${GITHUB_USERNAME}/${GITHUB_REPO_NAME}:latest
    container_name: jdc-nextjs-1
    restart: unless-stopped
    environment:
      - DATABASE_URL=mysql://${MYSQL_NEXTJS_USER}:${MYSQL_NEXTJS_PASSWORD}@jdc-orders-db:3306/${MYSQL_NEXTJS_DATABASE}
      - INSTANCE_ID=nextjs-1

      # Next env.
      # WooCommerce keys
      - WOOCOMMERCE_CONSUMER_KEY=${WOOCOMMERCE_CONSUMER_KEY}
      - WOOCOMMERCE_CONSUMER_SECRET=${WOOCOMMERCE_CONSUMER_SECRET}

      # MailPoet API
      - MAILPOET_API_KEY=${MAILPOET_API_KEY}

      # Cron
      - CRON_SECRET_KEY=${CRON_SECRET_KEY}

      # Redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}

      # CSRF Protection
      - CSRF_SECRET=${CSRF_SECRET}
      - WEBHOOK_API_KEY=${WEBHOOK_API_KEY}

      # Google reCAPTCHA v3 keys
      - RECAPTCHA_SECRET_KEY=${RECAPTCHA_SECRET_KEY}

      # 0.0.0.0 for internal docker accessibility without ports exposed (i.e. traefik)
      - HOST=${HOST}
      - PORT=${PORT}

      # Stripe keys
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}

      # Redis
      - REDIS_URL=${REDIS_URL}
    depends_on:
      jdc-orders-db:
        condition: service_healthy
      jdc-redis:
        condition: service_healthy
    networks:
      - jdc-network
    labels:
      - "traefik.enable=true"
      # Service configuration (duplicate in both instances for resilience)
      - "traefik.http.routers.nextjs.rule=PathPrefix(`/`)"
      - "traefik.http.routers.nextjs.service=nextjs-service"
      - "traefik.http.services.nextjs-service.loadbalancer.sticky.cookie=true"
      - "traefik.http.services.nextjs-service.loadbalancer.sticky.cookie.name=jdc_instance"
      - "traefik.http.services.nextjs-service.loadbalancer.healthcheck.path=/api/health"
      - "traefik.http.services.nextjs-service.loadbalancer.healthcheck.interval=30s"
      - "traefik.http.services.nextjs-service.loadbalancer.server.port=3000"
      
      # Watchtower lifecycle hooks
      - "com.centurylinklabs.watchtower.lifecycle.pre-update=curl -f http://jdc-nextjs-2:3000/api/health || (echo 'Other instance unhealthy, aborting update' && exit 1)"
      - "com.centurylinklabs.watchtower.lifecycle.post-update=sh -c 'sleep 10 && for i in 1 2 3 4 5; do curl -f http://jdc-nextjs-1:3000/api/health && exit 0 || sleep 5; done; exit 1'"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://jdc-nextjs-1:3000/api/health"]
      interval: 30s
      timeout: 10s
      start_period: 15s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
    deploy:
      resources:
        reservations:
          memory: 200M  # Needs: Prisma client, Stripe SDK, WooCommerce API calls
    oom_score_adj: -500  # Protect, but less than DB

  # Next.js Instance 2
  nextjs-2:
    image: ghcr.io/${GITHUB_USERNAME}/${GITHUB_REPO_NAME}:latest
    container_name: jdc-nextjs-2
    restart: unless-stopped
    environment:
      - DATABASE_URL=mysql://${MYSQL_NEXTJS_USER}:${MYSQL_NEXTJS_PASSWORD}@jdc-orders-db:3306/${MYSQL_NEXTJS_DATABASE}
      - INSTANCE_ID=nextjs-2

      # Next env.
      # WooCommerce keys
      - WOOCOMMERCE_CONSUMER_KEY=${WOOCOMMERCE_CONSUMER_KEY}
      - WOOCOMMERCE_CONSUMER_SECRET=${WOOCOMMERCE_CONSUMER_SECRET}

      # MailPoet API
      - MAILPOET_API_KEY=${MAILPOET_API_KEY}

      # Cron
      - CRON_SECRET_KEY=${CRON_SECRET_KEY}

      # Redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_PORT=${REDIS_PORT}

      # CSRF Protection
      - CSRF_SECRET=${CSRF_SECRET}
      - WEBHOOK_API_KEY=${WEBHOOK_API_KEY}

      # Google reCAPTCHA v3 keys
      - RECAPTCHA_SECRET_KEY=${RECAPTCHA_SECRET_KEY}

      # 0.0.0.0 for internal docker accessibility without ports exposed (i.e. traefik)
      - HOST=${HOST}
      - PORT=${PORT}

      # Stripe keys
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}

      # Redis
      - REDIS_URL=${REDIS_URL}
    depends_on:
      jdc-orders-db:
        condition: service_healthy
      jdc-redis:
        condition: service_healthy
    networks:
      - jdc-network
    labels:
      - "traefik.enable=true"
      # Service configuration (duplicate in both instances for resilience)
      - "traefik.http.routers.nextjs.rule=PathPrefix(`/`)"
      - "traefik.http.routers.nextjs.service=nextjs-service"
      - "traefik.http.services.nextjs-service.loadbalancer.sticky.cookie=true"
      - "traefik.http.services.nextjs-service.loadbalancer.sticky.cookie.name=jdc_instance"
      - "traefik.http.services.nextjs-service.loadbalancer.healthcheck.path=/api/health"
      - "traefik.http.services.nextjs-service.loadbalancer.healthcheck.interval=30s"
      - "traefik.http.services.nextjs-service.loadbalancer.server.port=3000"
      
      # Watchtower lifecycle hooks
      - "com.centurylinklabs.watchtower.lifecycle.pre-update=curl -f http://jdc-nextjs-1:3000/api/health || (echo 'Other instance unhealthy, aborting update' && exit 1)"
      - "com.centurylinklabs.watchtower.lifecycle.post-update=sh -c 'sleep 10 && for i in 1 2 3 4 5; do curl -f http://jdc-nextjs-2:3000/api/health && exit 0 || sleep 5; done; exit 1'"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://jdc-nextjs-2:3000/api/health"]
      interval: 30s
      timeout: 10s
      start_period: 15s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
    deploy:
      resources:
        reservations:
          memory: 200M
    oom_score_adj: -500


  wordpress:
    ports:
      - "127.0.0.1:8080:80"

  # ============================================
  # INFRASTRUCTURE: Load Balancing
  # ============================================
  
  traefik:
    image: traefik:3.6
    # image: traefik:latest
    container_name: jdc-traefik
    restart: unless-stopped
    command:
      - "--api.dashboard=false"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.ping.address=:6969"
      - "--log.level=INFO"
      - "--metrics.prometheus=true"
      - "--ping=true"
      - "--ping.entrypoint=ping"
    ports:
      - "127.0.0.1:3000:80"  # Traefik will listen on 3000 and forward to Next.js instances
      # - "6969:6969"
      - "127.0.0.1:6969:6969"  # ← Bind metrics to localhost only (Should be for internal access only)
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - jdc-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6969/ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
    deploy:
      resources:
        reservations:
          memory: 48M  # Very lightweight reverse proxy
    oom_score_adj: -100  # Keep it alive for routing

  # ============================================
  # UTILITY: Kill these first if needed
  # ============================================

  ntfy:
    image: binwiederhier/ntfy:latest
    container_name: jdc-ntfy
    restart: unless-stopped
    command:
      - serve
    environment:
      - TZ=America/New_York
      - NTFY_BASE_URL=https://jardindeschefs.ca
      - NTFY_CACHE_FILE=/var/cache/ntfy/cache.db
      - NTFY_AUTH_FILE=/var/lib/ntfy/user.db
      - NTFY_AUTH_DEFAULT_ACCESS=deny-all
      - NTFY_BEHIND_PROXY=true
      - NTFY_ENABLE_SIGNUP=false
      - NTFY_ENABLE_LOGIN=true
    volumes:
      - ntfy-cache:/var/cache/ntfy
      - ntfy-data:/var/lib/ntfy
    networks:
      - jdc-network
    ports:
      - "127.0.0.1:8081:80"
    healthcheck:
      test: ["CMD-SHELL", "wget -q --tries=1 http://localhost:80/v1/health -O - | grep -iq '\"healthy\"'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        reservations:
          memory: 32M
    oom_score_adj: 800  # Kill first - just notifications

  # Trying docker socket proxy to make watchtower more secure
  # docker-socket-proxy:
  #   image: tecnativa/docker-socket-proxy
  #   container_name: docker-socket-proxy
  #   restart: unless-stopped
  #   environment:
  #     - LOG_LEVEL=info
  #     - CONTAINERS=1
  #     - IMAGES=1
  #     - NETWORKS=1
  #     - ALLOW_START=1
  #     - ALLOW_RESTARTS=1
  #     - ALLOW_STOP=1
  #     - EVENTS=1
  #     - PING=1
  #     - VERSION=1
  #     - VOLUMES=1
  #     - POST=1
  #     - SERVICES=0
  #     - INFO=0
  #     - TASKS=0
  #     - AUTH=0
  #     - SECRETS=0
  #     - BUILD=0
  #     - COMMIT=0
  #     - CONFIGS=0
  #     - DISTRIBUTION=0
  #     - EXEC=0
  #     - GRPC=0
  #     - NODES=0
  #     - PLUGINS=0
  #     - SESSION=0
  #     - SWARM=0
  #     - SYSTEM=0
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #   networks:
  #     - jdc-network
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "5m"
  #       max-file: "2"

  watchtower:
    image: nickfedor/watchtower:latest
    container_name: jdc-watchtower
    restart: unless-stopped
    volumes: # this mount is risky and gives watchtower access to all docker actions!
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      # - DOCKER_HOST=tcp://docker-socket-proxy:2375
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_INCLUDE_RESTARTING=true
      - WATCHTOWER_ROLLING_RESTART=true
      - WATCHTOWER_LIFECYCLE_HOOKS=true
      - WATCHTOWER_TIMEOUT=30s
      - WATCHTOWER_POLL_INTERVAL=300  # Check every 5 minutes
      - WATCHTOWER_NOTIFICATIONS=shoutrrr
      - WATCHTOWER_NOTIFICATION_REPORT=true
      - WATCHTOWER_NOTIFICATION_SKIP_TITLE=true
      - WATCHTOWER_NOTIFICATION_URL=generic+https://jardindeschefs.ca/ntfy/jdc-server?@authorization=Bearer+${NTFY_WATCHTOWER_TOKEN}
      - 'WATCHTOWER_NOTIFICATION_TEMPLATE={{- if .Report -}}{{- if or .Report.Updated .Report.Restarted .Report.Failed -}}{{len .Report.Scanned}} Scanned, {{len .Report.Updated}} Updated, {{len .Report.Restarted}} Restarted, {{len .Report.Failed}} Failed{{"\n"}}{{- range .Report.Updated}}- {{.Name}} ({{.ImageName}}): {{.CurrentImageID.ShortID}} → {{.LatestImageID.ShortID}}{{"\n"}}{{- end -}}{{- range .Report.Restarted}}- {{.Name}} ({{.ImageName}}): Restarted{{"\n"}}{{- end -}}{{- range .Report.Failed}}- {{.Name}} ({{.ImageName}}): FAILED - {{.Error}}{{"\n"}}{{- end -}}{{- end -}}{{- end -}}'
      - WATCHTOWER_MONITOR_ONLY=false
      - WATCHTOWER_NO_STARTUP_MESSAGE=false
    # command: --interval 300 jdc-nextjs-1 jdc-nextjs-2
    command: --interval 300 jdc-nextjs-1 jdc-nextjs-2 jdc-watchtower
    networks:
      - jdc-network
    depends_on:
      # docker-socket-proxy:
      #   condition: service_started
      ntfy:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
    deploy:
      resources:
        reservations:
          memory: 32M
    oom_score_adj: 900  # Kill second - only needed for updates

  watchtower-infra:
    image: nickfedor/watchtower:latest
    container_name: jdc-watchtower-infra
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_ROLLING_RESTART=false
      - WATCHTOWER_POLL_INTERVAL=3600  # Check every hour (less aggressive)
      - WATCHTOWER_NOTIFICATIONS=shoutrrr
      - WATCHTOWER_NOTIFICATION_REPORT=true
      - WATCHTOWER_NOTIFICATION_SKIP_TITLE=true
      - WATCHTOWER_NOTIFICATION_URL=generic+https://jardindeschefs.ca/ntfy/jdc-server?@authorization=Bearer+${NTFY_WATCHTOWER_TOKEN}
      - 'WATCHTOWER_NOTIFICATION_TEMPLATE={{- if .Report -}}{{- if or .Report.Updated .Report.Restarted .Report.Failed -}}{{len .Report.Scanned}} Scanned, {{len .Report.Updated}} Updated, {{len .Report.Restarted}} Restarted, {{len .Report.Failed}} Failed{{"\n"}}{{- range .Report.Updated}}- {{.Name}} ({{.ImageName}}): {{.CurrentImageID.ShortID}} → {{.LatestImageID.ShortID}}{{"\n"}}{{- end -}}{{- range .Report.Restarted}}- {{.Name}} ({{.ImageName}}): Restarted{{"\n"}}{{- end -}}{{- range .Report.Failed}}- {{.Name}} ({{.ImageName}}): FAILED - {{.Error}}{{"\n"}}{{- end -}}{{- end -}}{{- end -}}'
      - WATCHTOWER_MONITOR_ONLY=false
      - WATCHTOWER_NO_STARTUP_MESSAGE=false
    command: --interval 3600 jdc-wp-app jdc-traefik jdc-ntfy jdc-watchtower-infra
    networks:
      - jdc-network
    depends_on:
      # docker-socket-proxy:
      #   condition: service_started
      ntfy:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
    deploy:
      resources:
        reservations:
          memory: 32M
    oom_score_adj: 900  # Kill second - only needed for updates

  health-monitor:
    image: alpine:latest
    container_name: jdc-health-monitor
    restart: unless-stopped
    volumes:
      - ../monitoring/health-check.sh:/health-check.sh
    environment:
      - NTFY_URL=https://jardindeschefs.ca/ntfy/jdc-server
      - NTFY_TOKEN=${NTFY_HEALTHMONITOR_TOKEN}
      - CHECK_INTERVAL=60
    # Install bash and curl, then run the script with bash
    command: >
      sh -c "
        apk add --no-cache bash curl &&
        chmod +x /health-check.sh &&
        bash /health-check.sh
      "
    networks:
      - jdc-network
    depends_on:
      jdc-orders-db:
        condition: service_healthy
      jdc-redis:
        condition: service_healthy
      traefik:
        condition: service_healthy
      nextjs-1:
        condition: service_started
      nextjs-2:
        condition: service_started
      ntfy:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
    deploy:
      resources:
        reservations:
          memory: 24M
    oom_score_adj: 950  # Kill third

  # Cron Service for Next.js cleanup tasks and database backups
  cron:
    build:
      context: ./cron
      dockerfile: Dockerfile
    container_name: jdc-cron
    restart: unless-stopped
    volumes:
      - ./cron/entrypoint.sh:/entrypoint.sh
      - ./cron/keys:/keys:ro
      - ./cron/backups:/backups
      - ./wordpress:/wordpress:ro
    environment:
      - CRON_SECRET_KEY=${CRON_SECRET_KEY}
      - TRAEFIK_URL=http://traefik:80
      - MYSQL_WORDPRESS_ROOT_PASSWORD=${MYSQL_WORDPRESS_ROOT_PASSWORD}
      - MYSQL_NEXTJS_ROOT_PASSWORD=${MYSQL_NEXTJS_ROOT_PASSWORD}
      - MYSQL_NEXTJS_DATABASE=${MYSQL_NEXTJS_DATABASE}
      - NEXTCLOUD_URL=${NEXTCLOUD_URL}
      - NEXTCLOUD_USER=${NEXTCLOUD_USER}
      - NEXTCLOUD_PASSWORD=${NEXTCLOUD_PASSWORD}
    command: /entrypoint.sh
    networks:
      - jdc-network
      - wp-network
    depends_on:
      - db
      - jdc-orders-db
      - traefik
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        reservations:
          memory: 32M
    oom_score_adj: 850  # Kill if needed - backups can wait

volumes:
  ntfy-cache:
  ntfy-data:
